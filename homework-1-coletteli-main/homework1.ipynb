{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (100 points)\n",
    "\n",
    "The goal of this homework is to practice using [pandas](https://pypi.org/project/pandas/) methods. If your:\n",
    "\n",
    "1. code is taking a long time to run\n",
    "2. code involves for loops or while loops\n",
    "\n",
    "look through the pandas documentation for alternatives.\n",
    "\n",
    "## Exercise 1 (60 points)\n",
    "\n",
    "This exercise will use the [Titanic dataset](https://www.kaggle.com/c/titanic/data) (https://www.kaggle.com/c/titanic/data). Download the file named `train.csv` and place it in the same folder as this notebook.\n",
    "\n",
    "a) Write a function that reads in a filepath to a csv and returns the DataFrame. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3aabc0c7114b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'file_name.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv ('file_name.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write a function that returns the number of rows that have at least one empty column value - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_nans(df):\n",
    "    nf = df(df.isnull().any(axis=1))\n",
    "    return len(nf)\n",
    "\n",
    "print(\"there are \" +  str(num_nans(df)) + \" rows with at least one empty value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that removes all columns with more than 200 NaN values - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(df):\n",
    "    return  df.dropna(axis = 1, thresh = 691)\n",
    "\n",
    "df = drop_na(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Write a function that replaces `male` with 0 and `female` with 1 - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numerical(df):\n",
    "    func = df.get('Sex')\n",
    "    func = func.replace(toreplace= 'female',value = 1)\n",
    "    func = func.replace(toreplace= 'male', value = 0)\n",
    "    return func\n",
    "\n",
    "df['Sex'] = to_numerical(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)  Write a function that adds four columns `First Name`, `Middle Name`, `Last Name`, and `Title` corresponding to the value in the `name` column. - (5 points) \n",
    "\n",
    "For example: `Braund, Mr. Owen Harris` would be: \n",
    "\n",
    "|First Name | Middle Name | Last Name | Title |\n",
    "|-----------|-------------|-----------|-------|\n",
    "| Owen      |  Harris     |  Braund   | Mr    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names (df):\n",
    "    names = df.get(\"Name\")\n",
    "    col = pd.DataFrame(columns =['First Name', 'Middle Name','Last Name', 'Title' ] )\n",
    "    names = names.str.split(\",\", n=1)\n",
    "    names = pd.DataFrame(names.tolist(), index = names.index)\n",
    "    names[1] = names[1].str.split('.',n=1)\n",
    "    names[[1,2]]= pd.DataFrame(names[1].tolist(), index = names.index)\n",
    "    names[2]= names[2].str.split(n=1)\n",
    "    names[[2,3]] = pd.DataFrame(names[2].tolist(), index = names.index)\n",
    "\n",
    "    col['First Name'] = names[2]\n",
    "    col[ 'Middle Name'] = names[3]\n",
    "    col[ 'Last Name'] = names[0]\n",
    "    col['Title' ] = names[1]\n",
    "\n",
    "df[['First Name', 'Middle Name', 'Last Name', 'Title']] = extract_names(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Write a function that replaces all missing ages with the average age - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_mean(df):\n",
    "    hd= df.get('Age')\n",
    "    avga= hd.mean()\n",
    "    hd= hd.replace(to_replace=np.nan, value=avga)\n",
    "    return hd\n",
    "    \n",
    "df['Age'] = replace_with_mean(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of questions focus on visualization. Please use pandas and [matplotlib](https://pypi.org/project/matplotlib/) for all plotting.\n",
    "\n",
    "g) Plot a bar chart of the average age of those that survived and did not survive. Briefly comment on what you observe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_survived= df[(df['Survived']==1)]\n",
    "total_died=df[(df['Survived']==0)]\n",
    "\n",
    "avgS=(total_survived['Fare']).mean()\n",
    "avgD=(total_died['Fare']).mean\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.title(\"Avg fare survived vs dead\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones who survived paid more than the ones who died"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Plot a bar chart of the proportion that survived for male and female. Briefly comment on what you observe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_survived = df[df['Survived'] == 1].get('Sex').count()\n",
    "female_survived = df[df['Survived'] == 1].get('Sex').sum() / total_survived\n",
    "male_survived = (total_survived - (female_survived * total_survived)) / total_survived\n",
    "\n",
    "df = pd.DataFrame({'Survival' : ['Male', 'Female'], 'Proportion' : [male_survived, female_survived]})\n",
    "df.plot.bar(x = 'Survival', y = 'Proportion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Plot a bar chart of the proportion that survived for each title. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Plot a bar chart of the average fare for those that survived and those that did not survive. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = df[(df['Survived'] == 1)]\n",
    "died = df[(df['Survived'] == 0)]\n",
    "avgS = (survived['Age']).mean()\n",
    "avgD = (died['Age']).mean()\n",
    "x = ''\n",
    "plt.bar('survived', avgS)\n",
    "plt.bar('died',avgD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Create a boxplot for the fare of those that survived and those that did not survive. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Create a function to subtract the mean fare from the actual fare then divide by the standard deviation - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_fare(df):\n",
    "    far = df.get('Fare')\n",
    "    average = far.mean()\n",
    "    std = far.std()\n",
    "    far = far.sub(average)\n",
    "    far = far.div(std)\n",
    "    return far\n",
    "\n",
    "df['Fare'] = norm_fare(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Remove all non-numerical columns from the dataframe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select_dtypes(include = 'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m) Ignoring passenger ID, write a function that returns the names of the N most similar pairs of passengers using the euclidean distance? - (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_most_similar_pairs(df, N):\n",
    "    return # < your code here >\n",
    "\n",
    "print(\"The 3 most similar passengers are: \" + str(N_most_similar_pairs(df, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - (40 points)\n",
    "\n",
    "Another way to get data is by using APIs. Here we will be using the google books API (https://developers.google.com/books/docs/overview)\n",
    "\n",
    "a) Create a list with these topic strings: Python; Data Science; Data Analysis; Machine Learning; and Deep \n",
    "Learning. Use these topics, one at a time, to query the Google Books API by modifying the code below. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "    Google Books Api\n",
    "    See: https://developers.google.com/books/\n",
    "\"\"\"\n",
    "\n",
    "def get(topic=\"\"):\n",
    "    BASEURL = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.get(BASEURL + \"?q=\" + topic, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "\n",
    "    return response\n",
    "\n",
    "python = get(\"Python\")\n",
    "data_science = get(topic=\"Data Science\")\n",
    "data_analytics = get(topic=\"Data Analysis\")\n",
    "machine_learning = get(topic= 'Machine Learning')\n",
    "deep_learning = get(topic=\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) For each returned JSON string: Convert the JSON string to a dict using `loads( )` then use this to convert it to a DataFrame: `pd.json_normalize( thedict['items'] )`. Then save them as `.csv`. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythnorm= pd.json_normalize(python['items'])\n",
    "dsnorma= pd.json_normalize(data_science['items'])\n",
    "danonorma= pd.json_normalize(data_analytics['items'])\n",
    "machlearnnorm=pd.json_normalize(machine_learning['items'])\n",
    "deepleaarnnorm= pd.json_normalize(deep_learning['items'])\n",
    "\n",
    "pythnorm.to_csv('Cpython.csv',encoding='utf-8')\n",
    "dsnorma.to_csv('CDataScience.csv',encoding='utf-8')\n",
    "danonorma.to_csv('CDataAnalytics.csv',encoding='utf-8')\n",
    "machlearnnorm.to_csv('CMachineLearning.csv',encoding='utf-8')\n",
    "deepleaarnnorm.to_csv('CDeepLearning.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For each DataFrame, relabel `volumeInfo.title` as `Title` and `volumeInfo.authors` as `Authors`. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythnorm.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})\n",
    "dsnorma.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})\n",
    "danonorma.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})\n",
    "machlearnnorm.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})\n",
    "deepleaarnnorm.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) For each DataFrame create a new column called `Topic` with the name of the topic from the API query above. Then merge all DataFrames into one and save it to a new `.csv` file. - (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pythnorm['Topic']='Python'\n",
    "dsnorma['Topic']=' Data Science '\n",
    "danonorma['Topic']=' Data Analytics '\n",
    "machlearnnorm['Topic']=' Machine Learning '\n",
    "deepleaarnnorm['Topic']=' Deep Learning '\n",
    "\n",
    "framing=[pythnorm,dsnorma,danonorma,machlearnnorm,deepleaarnnorm]\n",
    "file= pd.concat(framing)\n",
    "file.to_csv('alltopics.csv',encoding='utf-8')\n",
    "file= file.rename(columns={'volumeInfo.title':'Title', 'volumeInfo.authors':'Authors'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Write a function that returns all rows whose `Title` contains the word `Data` (case incensitive). - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtit=file[file['Title'].str.contains('Data')]\n",
    "print(newtit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Write a function that returns all rows whose `Authors` first or last name starts with the letter `E` - (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eAuthors(df):\n",
    "    auth = df\n",
    "    auth['Authors'] = df.get('Authors').astype('string')\n",
    "    auth = auth[auth['Authors'].str.contains('E')]\n",
    "    return auth"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
